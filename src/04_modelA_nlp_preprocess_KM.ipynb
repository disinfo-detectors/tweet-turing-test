{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Turing Test: Detecting Disinformation on Twitter  \n",
    "\n",
    "|          | Group #2 - Disinformation Detectors                     |\n",
    "|---------:|---------------------------------------------------------|\n",
    "| Members  | John Johnson, Katy Matulay, Justin Minnion, Jared Rubin |\n",
    "| Notebook | `xx_modelA_nlp_preprocess.ipynb`                        |\n",
    "| Purpose  | NLP-specific preprocessing for Model A                  |\n",
    "\n",
    "(todo: description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports from Python standard library\n",
    "\n",
    "# imports requiring installation\n",
    "#   connection to Google Cloud Storage\n",
    "from google.cloud import storage            # pip install google-cloud-storage\n",
    "from google.oauth2 import service_account   # pip install google-auth\n",
    "\n",
    "#  data science packages\n",
    "import numpy as np                          # pip install numpy\n",
    "import pandas as pd                         # pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports from tweet_turing.py\n",
    "import tweet_turing as tur      # note - different import approach from prior notebooks\n",
    "\n",
    "# imports from tweet_turing_paths.py\n",
    "from tweet_turing_paths import local_data_paths, local_snapshot_paths, gcp_data_paths, \\\n",
    "    gcp_snapshot_paths, gcp_project_name, gcp_bucket_name, gcp_key_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas options\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local or Cloud?\n",
    "\n",
    "Decide here whether to run notebook with local data or GCP bucket data\n",
    " - if the working directory of this notebook has a \"../data/\" folder with data loaded (e.g. working on local computer or have data files loaded to a cloud VM) then use the \"local files\" option and comment out the \"gcp bucket files\" option\n",
    " - if this notebook is being run from a GCP VM (preferrably in the `us-central1` location) then use the \"gcp bucket files\" option and comment out the \"local files\" option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option: local files\n",
    "local_or_cloud: str = \"local\"   # comment/uncomment this line or next\n",
    "\n",
    "# option: gcp bucket files\n",
    "#local_or_cloud: str = \"cloud\"   # comment/uncomment this line or previous\n",
    "\n",
    "# don't comment/uncomment for remainder of cell\n",
    "if (local_or_cloud == \"local\"):\n",
    "    data_paths = local_data_paths\n",
    "    snapshot_paths = local_snapshot_paths\n",
    "elif (local_or_cloud == \"cloud\"):\n",
    "    data_paths = gcp_data_paths\n",
    "    snapshot_paths = gcp_snapshot_paths\n",
    "else:\n",
    "    raise ValueError(\"Variable 'local_or_cloud' can only take on one of two values, 'local' or 'cloud'.\")\n",
    "    # subsequent cells will not do this final \"else\" check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell only needs to run its code if local_or_cloud==\"cloud\"\n",
    "#   (though it is harmless if run when local_or_cloud==\"local\")\n",
    "gcp_storage_client: storage.Client = None\n",
    "gcp_bucket: storage.Bucket = None\n",
    "\n",
    "if (local_or_cloud == \"cloud\"):\n",
    "    gcp_storage_client = tur.get_gcp_storage_client(project_name=gcp_project_name, key_file=gcp_key_file)\n",
    "    gcp_bucket = tur.get_gcp_bucket(storage_client=gcp_storage_client, bucket_name=gcp_bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Load Dataset\n",
    "\n",
    "Core dataset, as prepared by prior notebook `03_eda.ipynb`, will be loaded as \"`df_full`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workaround- delete\n",
    "\n",
    "import os\n",
    "os.chdir('/Users/katymatulay/Documents/Drexel - Grad School/08 Winter 2023/DSCI592/data')\n",
    "df_full = pd.read_parquet(\"../data/data_after_03_eda.parquet.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "../data/snapshot/data_after_03_eda.parquet.gz",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-71a0cc721deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlocal_or_cloud\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"local\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparq_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pyarrow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlocal_or_cloud\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cloud\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mpass\u001b[0m    \u001b[0;31m# TODO: implement loading of cloud file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \"\"\"\n\u001b[1;32m    316\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"use_pandas_metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         result = self.api.parquet.read_table(\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         ).to_pandas()\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2822\u001b[0m             )\n\u001b[1;32m   2823\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m             dataset = _ParquetDatasetV2(\n\u001b[0m\u001b[1;32m   2825\u001b[0m                 \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m                 \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_paths, filesystem, filters, partitioning, read_dictionary, buffer_size, memory_map, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, schema, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2421\u001b[0m                 infer_dictionary=True)\n\u001b[1;32m   2422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2423\u001b[0;31m         self._dataset = ds.dataset(path_or_paths, filesystem=filesystem,\n\u001b[0m\u001b[1;32m   2424\u001b[0m                                    \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparquet_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m                                    \u001b[0mpartitioning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36mdataset\u001b[0;34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_filesystem_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_is_path_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36m_filesystem_dataset\u001b[0;34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths_or_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_multiple_sources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths_or_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_single_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     options = FileSystemFactoryOptions(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36m_ensure_single_source\u001b[0;34m(path, filesystem)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mpaths_or_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths_or_selector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: ../data/snapshot/data_after_03_eda.parquet.gz"
     ]
    }
   ],
   "source": [
    "# note this cell requires package `pyarrow` to be installed in environment\n",
    "parq_filename: str = \"data_after_03_eda.parquet.gz\"\n",
    "parq_path: str = f\"{snapshot_paths['parq_snapshot']}{parq_filename}\"\n",
    "\n",
    "if (local_or_cloud == \"local\"):\n",
    "    df_full = pd.read_parquet(parq_path, engine='pyarrow')\n",
    "elif (local_or_cloud == \"cloud\"):\n",
    "    pass    # TODO: implement loading of cloud file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Subset Data\n",
    "\n",
    "Data subset will be created as simply \"`df`\" for brevity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_author_id</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>region</th>\n",
       "      <th>language</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>updates</th>\n",
       "      <th>post_type</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>...</th>\n",
       "      <th>tco1_step1</th>\n",
       "      <th>data_source</th>\n",
       "      <th>has_url</th>\n",
       "      <th>emoji_text</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>class</th>\n",
       "      <th>following_ratio</th>\n",
       "      <th>class_numeric</th>\n",
       "      <th>RUS_lett_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2812169</th>\n",
       "      <td>23297570</td>\n",
       "      <td>ProfJamesLogan</td>\n",
       "      <td>#W1A is genius</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>lt</td>\n",
       "      <td>5130</td>\n",
       "      <td>14835</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>verified_random</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-26 21:55:02+00:00</td>\n",
       "      <td>Verified</td>\n",
       "      <td>0.345781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492472</th>\n",
       "      <td>119709295</td>\n",
       "      <td>clairybrowne</td>\n",
       "      <td>RT @PenelopeAAustin: S T A R Ûæ≠™ M A N ! Into this.. Px https://t.co/mQ0oxPaJyE</td>\n",
       "      <td>Your heart</td>\n",
       "      <td>lt</td>\n",
       "      <td>1349</td>\n",
       "      <td>3194</td>\n",
       "      <td>1</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.theguardian.com/music/2016/jan/18/david-bowie-astronomers-give-the-starman-his-own-constellation?CMP=share_btn_fb</td>\n",
       "      <td>verified_random</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-19 10:33:25+00:00</td>\n",
       "      <td>Verified</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502564</th>\n",
       "      <td>704344867</td>\n",
       "      <td>PenelopeAAustin</td>\n",
       "      <td>S T A R Ûæ≠™ M A N ! Into this.. Px https://t.co/mQ0oxPaJyE</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>lt</td>\n",
       "      <td>714</td>\n",
       "      <td>726</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.theguardian.com/music/2016/jan/18/david-bowie-astronomers-give-the-starman-his-own-constellation?CMP=share_btn_fb</td>\n",
       "      <td>verified_random</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-19 09:59:18+00:00</td>\n",
       "      <td>Verified</td>\n",
       "      <td>0.982118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3576325</th>\n",
       "      <td>307596372</td>\n",
       "      <td>LanhNguyenFilms</td>\n",
       "      <td>LTE is 4G. (@YouTube http://t.co/qmAJDDv1M8)</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>lt</td>\n",
       "      <td>199</td>\n",
       "      <td>2973</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>http://youtu.be/FPrA5TmN7wc?a</td>\n",
       "      <td>verified_random</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-07-06 01:56:10+00:00</td>\n",
       "      <td>Verified</td>\n",
       "      <td>0.066913</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        external_author_id           author  \\\n",
       "2812169           23297570   ProfJamesLogan   \n",
       "3492472          119709295     clairybrowne   \n",
       "3502564          704344867  PenelopeAAustin   \n",
       "3576325          307596372  LanhNguyenFilms   \n",
       "\n",
       "                                                                               content  \\\n",
       "2812169                                                                 #W1A is genius   \n",
       "3492472  RT @PenelopeAAustin: S T A R Ûæ≠™ M A N ! Into this.. Px https://t.co/mQ0oxPaJyE   \n",
       "3502564                       S T A R Ûæ≠™ M A N ! Into this.. Px https://t.co/mQ0oxPaJyE   \n",
       "3576325                                   LTE is 4G. (@YouTube http://t.co/qmAJDDv1M8)   \n",
       "\n",
       "              region language  following  followers  updates  post_type  \\\n",
       "2812169   London, UK       lt       5130      14835        3        NaN   \n",
       "3492472   Your heart       lt       1349       3194        1  retweeted   \n",
       "3502564         <NA>       lt        714        726        4        NaN   \n",
       "3576325  Kansas City       lt        199       2973        0        NaN   \n",
       "\n",
       "         is_retweet  ...  \\\n",
       "2812169         0.0  ...   \n",
       "3492472         1.0  ...   \n",
       "3502564         0.0  ...   \n",
       "3576325         0.0  ...   \n",
       "\n",
       "                                                                                                                            tco1_step1  \\\n",
       "2812169                                                                                                                           <NA>   \n",
       "3492472  https://www.theguardian.com/music/2016/jan/18/david-bowie-astronomers-give-the-starman-his-own-constellation?CMP=share_btn_fb   \n",
       "3502564  https://www.theguardian.com/music/2016/jan/18/david-bowie-astronomers-give-the-starman-his-own-constellation?CMP=share_btn_fb   \n",
       "3576325                                                                                                  http://youtu.be/FPrA5TmN7wc?a   \n",
       "\n",
       "             data_source has_url emoji_text  emoji_count  \\\n",
       "2812169  verified_random       0         []            0   \n",
       "3492472  verified_random       1         []            0   \n",
       "3502564  verified_random       1         []            0   \n",
       "3576325  verified_random       1         []            0   \n",
       "\n",
       "                     publish_date     class following_ratio class_numeric  \\\n",
       "2812169 2015-04-26 21:55:02+00:00  Verified        0.345781             0   \n",
       "3492472 2016-01-19 10:33:25+00:00  Verified        0.422222             0   \n",
       "3502564 2016-01-19 09:59:18+00:00  Verified        0.982118             0   \n",
       "3576325 2013-07-06 01:56:10+00:00  Verified        0.066913             0   \n",
       "\n",
       "         RUS_lett_count  \n",
       "2812169               0  \n",
       "3492472               0  \n",
       "3502564               0  \n",
       "3576325               0  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full[df_full['language']=='lt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_author_id</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>region</th>\n",
       "      <th>language</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>updates</th>\n",
       "      <th>post_type</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>...</th>\n",
       "      <th>tco1_step1</th>\n",
       "      <th>data_source</th>\n",
       "      <th>has_url</th>\n",
       "      <th>emoji_text</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>class</th>\n",
       "      <th>following_ratio</th>\n",
       "      <th>class_numeric</th>\n",
       "      <th>RUS_lett_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>839000000000000000</td>\n",
       "      <td>1LORENAFAVA1</td>\n",
       "      <td>Come vedere Juventus-Milan in streaming o in tv https://t.co/NHlb4OgXXY</td>\n",
       "      <td>Italy</td>\n",
       "      <td>en</td>\n",
       "      <td>416</td>\n",
       "      <td>61</td>\n",
       "      <td>249</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>http://ift.tt/2nnaPwn</td>\n",
       "      <td>Troll</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-10 18:21:00+00:00</td>\n",
       "      <td>Troll</td>\n",
       "      <td>6.709677</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>839000000000000000</td>\n",
       "      <td>1LORENAFAVA1</td>\n",
       "      <td>#SerieA in campo #JuventusMilan LIVE e FOTO https://t.co/zR8rrsmSPL</td>\n",
       "      <td>Italy</td>\n",
       "      <td>en</td>\n",
       "      <td>416</td>\n",
       "      <td>62</td>\n",
       "      <td>255</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>http://ow.ly/luNF309Nh2L</td>\n",
       "      <td>Troll</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-10 20:01:00+00:00</td>\n",
       "      <td>Troll</td>\n",
       "      <td>6.603175</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>839000000000000000</td>\n",
       "      <td>1LORENAFAVA1</td>\n",
       "      <td>#Privacy, come difenderla on line (e con le #App) https://t.co/t4A4GisVyE https://t.co/ET8FkCSct9</td>\n",
       "      <td>Italy</td>\n",
       "      <td>en</td>\n",
       "      <td>416</td>\n",
       "      <td>62</td>\n",
       "      <td>261</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>https://twitter.com/Adnkronos/status/840315104440680448/photo/1</td>\n",
       "      <td>Troll</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-10 21:37:00+00:00</td>\n",
       "      <td>Troll</td>\n",
       "      <td>6.603175</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>839000000000000000</td>\n",
       "      <td>1LORENAFAVA1</td>\n",
       "      <td>Come vedere Italia-Francia di rugby in tv e in streaming https://t.co/aKFgLcyljK</td>\n",
       "      <td>Italy</td>\n",
       "      <td>en</td>\n",
       "      <td>415</td>\n",
       "      <td>64</td>\n",
       "      <td>292</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>http://ift.tt/2ng5dVp</td>\n",
       "      <td>Troll</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-11 12:59:00+00:00</td>\n",
       "      <td>Troll</td>\n",
       "      <td>6.384615</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>839000000000000000</td>\n",
       "      <td>1LORENAFAVA1</td>\n",
       "      <td>Come vedere Genoa-Sampdoria, in tv o in streaming https://t.co/ew3hENEsYE</td>\n",
       "      <td>Italy</td>\n",
       "      <td>en</td>\n",
       "      <td>414</td>\n",
       "      <td>68</td>\n",
       "      <td>313</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>http://ift.tt/2nqCe06</td>\n",
       "      <td>Troll</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-11 18:58:00+00:00</td>\n",
       "      <td>Troll</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     external_author_id        author  \\\n",
       "415  839000000000000000  1LORENAFAVA1   \n",
       "416  839000000000000000  1LORENAFAVA1   \n",
       "417  839000000000000000  1LORENAFAVA1   \n",
       "418  839000000000000000  1LORENAFAVA1   \n",
       "419  839000000000000000  1LORENAFAVA1   \n",
       "\n",
       "                                                                                               content  \\\n",
       "415                            Come vedere Juventus-Milan in streaming o in tv https://t.co/NHlb4OgXXY   \n",
       "416                                #SerieA in campo #JuventusMilan LIVE e FOTO https://t.co/zR8rrsmSPL   \n",
       "417  #Privacy, come difenderla on line (e con le #App) https://t.co/t4A4GisVyE https://t.co/ET8FkCSct9   \n",
       "418                   Come vedere Italia-Francia di rugby in tv e in streaming https://t.co/aKFgLcyljK   \n",
       "419                          Come vedere Genoa-Sampdoria, in tv o in streaming https://t.co/ew3hENEsYE   \n",
       "\n",
       "    region language  following  followers  updates post_type  is_retweet  ...  \\\n",
       "415  Italy       en        416         61      249   RETWEET         1.0  ...   \n",
       "416  Italy       en        416         62      255   RETWEET         1.0  ...   \n",
       "417  Italy       en        416         62      261   RETWEET         1.0  ...   \n",
       "418  Italy       en        415         64      292   RETWEET         1.0  ...   \n",
       "419  Italy       en        414         68      313   RETWEET         1.0  ...   \n",
       "\n",
       "                                                          tco1_step1  \\\n",
       "415                                            http://ift.tt/2nnaPwn   \n",
       "416                                         http://ow.ly/luNF309Nh2L   \n",
       "417  https://twitter.com/Adnkronos/status/840315104440680448/photo/1   \n",
       "418                                            http://ift.tt/2ng5dVp   \n",
       "419                                            http://ift.tt/2nqCe06   \n",
       "\n",
       "    data_source has_url emoji_text  emoji_count              publish_date  \\\n",
       "415       Troll       1         []            0 2017-03-10 18:21:00+00:00   \n",
       "416       Troll       1         []            0 2017-03-10 20:01:00+00:00   \n",
       "417       Troll       1         []            0 2017-03-10 21:37:00+00:00   \n",
       "418       Troll       1         []            0 2017-03-11 12:59:00+00:00   \n",
       "419       Troll       1         []            0 2017-03-11 18:58:00+00:00   \n",
       "\n",
       "     class following_ratio class_numeric  RUS_lett_count  \n",
       "415  Troll        6.709677             1               0  \n",
       "416  Troll        6.603175             1               0  \n",
       "417  Troll        6.603175             1               0  \n",
       "418  Troll        6.384615             1               0  \n",
       "419  Troll        6.000000             1               0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full[df_full['account_category']=='NonEnglish'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['external_author_id', 'author', 'content', 'region', 'language',\n",
       "       'following', 'followers', 'updates', 'post_type', 'is_retweet',\n",
       "       'account_category', 'tweet_id', 'tco1_step1', 'data_source', 'has_url',\n",
       "       'emoji_text', 'emoji_count', 'publish_date', 'class', 'following_ratio',\n",
       "       'class_numeric', 'RUS_lett_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df=df_full[df_full['language']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = en_df[en_df['account_category']!='NonEnglish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Troll       2090304\n",
       "Verified    1506274\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Verified_User    1470028\n",
       "RightTroll        704953\n",
       "NewsFeed          596593\n",
       "LeftTroll         422141\n",
       "HashtagGamer      236091\n",
       "Commercial        112580\n",
       "Unknown            43191\n",
       "Fearmonger         11001\n",
       "NonEnglish             0\n",
       "Name: account_category, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df['account_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset parameters\n",
    "sample_fraction = 0.10  # within range (0.0, 1.0)\n",
    "random_seed = 3         # for reproducability, and \"the number of the counting shall be three\"\n",
    "\n",
    "# generate sample\n",
    "df = df_full.sample(frac=sample_fraction, random_state=random_seed).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataframe size:\t    2.74 GB\n",
      "Sampled dataframe size:\t    0.28 GB\n",
      "\n",
      "Full dataframe rows:\t  3,624,894\n",
      "Sampled dataframe rows:\t    362,489\n",
      "\n",
      "Full df class split:\t['58.4%', '41.6%']\n",
      "Sampled df class split:\t['58.4%', '41.6%']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BYTES_PER_GIGABYTE = 10**9  # using IEC-recommended conversion; https://en.wikipedia.org/wiki/Gigabyte#Base_10_(decimal)\n",
    "\n",
    "df_full_size_gb = df_full.memory_usage(deep=True).sum() / BYTES_PER_GIGABYTE\n",
    "df_size_gb = df.memory_usage(deep=True).sum() / BYTES_PER_GIGABYTE\n",
    "\n",
    "print(f\"Full dataframe size:\\t{df_full_size_gb:8.2f} GB\")\n",
    "print(f\"Sampled dataframe size:\\t{df_size_gb:8.2f} GB\\n\")\n",
    "\n",
    "print(f\"Full dataframe rows:\\t{len(df_full.index):>11,}\")\n",
    "print(f\"Sampled dataframe rows:\\t{len(df.index):>11,}\\n\")\n",
    "\n",
    "class_split_full = [f\"{x*100:0.1f}%\" for x in df_full['class'].value_counts().div(len(df_full.index)).tolist()]\n",
    "class_split_samp = [f\"{x*100:0.1f}%\" for x in df['class'].value_counts().div(len(df.index)).tolist()]\n",
    "\n",
    "print(f\"Full df class split:\\t{class_split_full}\")\n",
    "print(f\"Sampled df class split:\\t{class_split_samp}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a copy of sampled df so above steps don't need to be repeated everytime\n",
    "# note this cell requires package `pyarrow` to be installed in environment\n",
    "parq_filename: str = \"data_sample_ten_percent.parquet.gz\"\n",
    "parq_path: str = f\"{snapshot_paths['parq_snapshot']}{parq_filename}\"\n",
    "\n",
    "if (local_or_cloud == \"local\"):\n",
    "    df.to_parquet(parq_path, engine='pyarrow', index=False, compression='gzip')\n",
    "elif (local_or_cloud == \"cloud\"):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_parquet(\"../data/data_sample_ten_percent.parquet.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Troll       211873\n",
       "Verified    150616\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=\"I bet you didn't know that üôã, üôã‚Äç‚ôÇÔ∏è, and üôã‚Äç‚ôÄÔ∏è are three different emojis.\"\n",
    "test_replaced = demoji.replace_with_desc(test, \"'\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I bet you didn't know that 'person raising hand', 'man raising hand', and 'woman raising hand' are three different emojis.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_author_id</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>region</th>\n",
       "      <th>language</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>updates</th>\n",
       "      <th>post_type</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>...</th>\n",
       "      <th>tco1_step1</th>\n",
       "      <th>data_source</th>\n",
       "      <th>has_url</th>\n",
       "      <th>emoji_text</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>class</th>\n",
       "      <th>following_ratio</th>\n",
       "      <th>class_numeric</th>\n",
       "      <th>RUS_lett_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3272640600</td>\n",
       "      <td>EXQUOTE</td>\n",
       "      <td>'@J_cranee Doozling @jamiieeubanks Janel' @RamzelInDistres ‚òπR a m s l e e p y‚òπ @sebass_field Staff Zenji http://t.co/j71SGSGouC'</td>\n",
       "      <td>United States</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>356</td>\n",
       "      <td>30376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>https://twitter.com/safety/unsafe_link_warning?unsafe_link=http%3A%2F%2Fwww.FatLossAdvice.pw%2FTips%2FThe-best-compliment-you-dont-workout-and-you-look-like-that.asp</td>\n",
       "      <td>Troll</td>\n",
       "      <td>1</td>\n",
       "      <td>[frowning face, frowning face]</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-08-04 18:59:00+00:00</td>\n",
       "      <td>Troll</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>785341092862525440</td>\n",
       "      <td>youFamousEnough</td>\n",
       "      <td>RT @SLIKNATIONPROAM: üö®SLIK WIT IT MATCHING UP FOR SEASON 7üö®https://t.co/Pq0JpQQUTe  @youFamousEnough @MPBA2K</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>en</td>\n",
       "      <td>5954</td>\n",
       "      <td>32934</td>\n",
       "      <td>1</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.twitch.tv/anewman33</td>\n",
       "      <td>verified_random</td>\n",
       "      <td>1</td>\n",
       "      <td>[police car light, police car light]</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-20 03:05:13+00:00</td>\n",
       "      <td>Verified</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>362787242</td>\n",
       "      <td>OttoMatticBaby</td>\n",
       "      <td>RT @Joey_0806: @OttoMatticBaby listening to your music before a game üî•üî•üî•</td>\n",
       "      <td>Pennsylvania, USA</td>\n",
       "      <td>en</td>\n",
       "      <td>737</td>\n",
       "      <td>203692</td>\n",
       "      <td>1</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>verified_random</td>\n",
       "      <td>0</td>\n",
       "      <td>[fire, fire, fire]</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-04-26 21:21:55+00:00</td>\n",
       "      <td>Verified</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>66369181</td>\n",
       "      <td>DeptofDefense</td>\n",
       "      <td>Water delivery. Members of the üáµüá∑ #NationalGuard distribute üö∞ for the #Utuado community following #HurricaneMaria. https://t.co/OGGKrLVZ8j</td>\n",
       "      <td>The Pentagon, Washington, D.C.</td>\n",
       "      <td>en</td>\n",
       "      <td>471</td>\n",
       "      <td>6534141</td>\n",
       "      <td>1335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>https://twitter.com/DeptofDefense/status/914339088416825344/photo/1</td>\n",
       "      <td>verified_user</td>\n",
       "      <td>1</td>\n",
       "      <td>[flag: Puerto Rico, potable water]</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-10-01 04:00:00+00:00</td>\n",
       "      <td>Verified</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>26145732</td>\n",
       "      <td>AdamMcKola</td>\n",
       "      <td>@vex1zgooner @ManUtd @Arsenal Well it is cos United fans are Wenger In. üòÇüòÇüòÇ</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>en</td>\n",
       "      <td>974</td>\n",
       "      <td>212108</td>\n",
       "      <td>1</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>verified_random</td>\n",
       "      <td>0</td>\n",
       "      <td>[face with tears of joy, face with tears of joy, face with tears of joy]</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-04-14 15:20:14+00:00</td>\n",
       "      <td>Verified</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     external_author_id           author  \\\n",
       "44           3272640600          EXQUOTE   \n",
       "78   785341092862525440  youFamousEnough   \n",
       "83            362787242   OttoMatticBaby   \n",
       "128            66369181    DeptofDefense   \n",
       "171            26145732       AdamMcKola   \n",
       "\n",
       "                                                                                                                                        content  \\\n",
       "44             '@J_cranee Doozling @jamiieeubanks Janel' @RamzelInDistres ‚òπR a m s l e e p y‚òπ @sebass_field Staff Zenji http://t.co/j71SGSGouC'   \n",
       "78                                 RT @SLIKNATIONPROAM: üö®SLIK WIT IT MATCHING UP FOR SEASON 7üö®https://t.co/Pq0JpQQUTe  @youFamousEnough @MPBA2K   \n",
       "83                                                                     RT @Joey_0806: @OttoMatticBaby listening to your music before a game üî•üî•üî•   \n",
       "128  Water delivery. Members of the üáµüá∑ #NationalGuard distribute üö∞ for the #Utuado community following #HurricaneMaria. https://t.co/OGGKrLVZ8j   \n",
       "171                                                                 @vex1zgooner @ManUtd @Arsenal Well it is cos United fans are Wenger In. üòÇüòÇüòÇ   \n",
       "\n",
       "                             region language  following  followers  updates  \\\n",
       "44                    United States       en          2        356    30376   \n",
       "78                      Houston, TX       en       5954      32934        1   \n",
       "83                Pennsylvania, USA       en        737     203692        1   \n",
       "128  The Pentagon, Washington, D.C.       en        471    6534141     1335   \n",
       "171                            <NA>       en        974     212108        1   \n",
       "\n",
       "      post_type  is_retweet  ...  \\\n",
       "44          NaN         0.0  ...   \n",
       "78    retweeted         1.0  ...   \n",
       "83    retweeted         1.0  ...   \n",
       "128         NaN         0.0  ...   \n",
       "171  replied_to         0.0  ...   \n",
       "\n",
       "                                                                                                                                                                tco1_step1  \\\n",
       "44   https://twitter.com/safety/unsafe_link_warning?unsafe_link=http%3A%2F%2Fwww.FatLossAdvice.pw%2FTips%2FThe-best-compliment-you-dont-workout-and-you-look-like-that.asp   \n",
       "78                                                                                                                                         https://www.twitch.tv/anewman33   \n",
       "83                                                                                                                                                                    <NA>   \n",
       "128                                                                                                    https://twitter.com/DeptofDefense/status/914339088416825344/photo/1   \n",
       "171                                                                                                                                                                   <NA>   \n",
       "\n",
       "         data_source has_url  \\\n",
       "44             Troll       1   \n",
       "78   verified_random       1   \n",
       "83   verified_random       0   \n",
       "128    verified_user       1   \n",
       "171  verified_random       0   \n",
       "\n",
       "                                                                   emoji_text  \\\n",
       "44                                             [frowning face, frowning face]   \n",
       "78                                       [police car light, police car light]   \n",
       "83                                                         [fire, fire, fire]   \n",
       "128                                        [flag: Puerto Rico, potable water]   \n",
       "171  [face with tears of joy, face with tears of joy, face with tears of joy]   \n",
       "\n",
       "     emoji_count              publish_date     class following_ratio  \\\n",
       "44             2 2015-08-04 18:59:00+00:00     Troll        0.005602   \n",
       "78             2 2017-03-20 03:05:13+00:00  Verified        0.180780   \n",
       "83             3 2015-04-26 21:21:55+00:00  Verified        0.003618   \n",
       "128            2 2017-10-01 04:00:00+00:00  Verified        0.000072   \n",
       "171            3 2017-04-14 15:20:14+00:00  Verified        0.004592   \n",
       "\n",
       "    class_numeric  RUS_lett_count  \n",
       "44              1               0  \n",
       "78              0               0  \n",
       "83              0               0  \n",
       "128             0               0  \n",
       "171             0               0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mini = df_sample[df_sample['emoji_count']>1][:5]\n",
    "df_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emoji_text(tweet_series: pd.Series) -> str:\n",
    "    ''' The following converts an emoji in a text string to a str enclosed with ''. '''\n",
    "    ##return demoji.replace_with_desc(tweet_series['content'], \"'\") \n",
    "    return demoji.replace_with_desc(tweet_series['content'], \" \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply convert_emoji_text\n",
    "new_column = df_mini.apply(convert_emoji_text, axis='columns')\n",
    "df_mini.loc[:, 'content2'] = new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'convert_emoji_text' from 'tweet_turing' (/Users/katymatulay/Documents/GitHub/tweet-turing-test/src/tweet_turing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-286a9a35ed4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# apply convert_emoji_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtweet_turing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_emoji_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnew_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_mini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_emoji_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_mini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'content2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'convert_emoji_text' from 'tweet_turing' (/Users/katymatulay/Documents/GitHub/tweet-turing-test/src/tweet_turing.py)"
     ]
    }
   ],
   "source": [
    "# apply convert_emoji_text\n",
    "from tweet_turing import convert_emoji_text\n",
    "new_column = df_mini.apply(convert_emoji_text, axis='columns')\n",
    "df_mini.loc[:, 'content2'] = new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>content2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>'@J_cranee Doozling @jamiieeubanks Janel' @RamzelInDistres ‚òπR a m s l e e p y‚òπ @sebass_field Staff Zenji http://t.co/j71SGSGouC'</td>\n",
       "      <td>'@J_cranee Doozling @jamiieeubanks Janel' @RamzelInDistres  frowning face R a m s l e e p y frowning face  @sebass_field Staff Zenji http://t.co/j71SGSGouC'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>RT @SLIKNATIONPROAM: üö®SLIK WIT IT MATCHING UP FOR SEASON 7üö®https://t.co/Pq0JpQQUTe  @youFamousEnough @MPBA2K</td>\n",
       "      <td>RT @SLIKNATIONPROAM:  police car light SLIK WIT IT MATCHING UP FOR SEASON 7 police car light https://t.co/Pq0JpQQUTe  @youFamousEnough @MPBA2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>RT @Joey_0806: @OttoMatticBaby listening to your music before a game üî•üî•üî•</td>\n",
       "      <td>RT @Joey_0806: @OttoMatticBaby listening to your music before a game  fire  fire  fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Water delivery. Members of the üáµüá∑ #NationalGuard distribute üö∞ for the #Utuado community following #HurricaneMaria. https://t.co/OGGKrLVZ8j</td>\n",
       "      <td>Water delivery. Members of the  flag: Puerto Rico  #NationalGuard distribute  potable water  for the #Utuado community following #HurricaneMaria. https://t.co/OGGKrLVZ8j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>@vex1zgooner @ManUtd @Arsenal Well it is cos United fans are Wenger In. üòÇüòÇüòÇ</td>\n",
       "      <td>@vex1zgooner @ManUtd @Arsenal Well it is cos United fans are Wenger In.  face with tears of joy  face with tears of joy  face with tears of joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                        content  \\\n",
       "44             '@J_cranee Doozling @jamiieeubanks Janel' @RamzelInDistres ‚òπR a m s l e e p y‚òπ @sebass_field Staff Zenji http://t.co/j71SGSGouC'   \n",
       "78                                 RT @SLIKNATIONPROAM: üö®SLIK WIT IT MATCHING UP FOR SEASON 7üö®https://t.co/Pq0JpQQUTe  @youFamousEnough @MPBA2K   \n",
       "83                                                                     RT @Joey_0806: @OttoMatticBaby listening to your music before a game üî•üî•üî•   \n",
       "128  Water delivery. Members of the üáµüá∑ #NationalGuard distribute üö∞ for the #Utuado community following #HurricaneMaria. https://t.co/OGGKrLVZ8j   \n",
       "171                                                                 @vex1zgooner @ManUtd @Arsenal Well it is cos United fans are Wenger In. üòÇüòÇüòÇ   \n",
       "\n",
       "                                                                                                                                                                      content2  \n",
       "44                '@J_cranee Doozling @jamiieeubanks Janel' @RamzelInDistres  frowning face R a m s l e e p y frowning face  @sebass_field Staff Zenji http://t.co/j71SGSGouC'  \n",
       "78                              RT @SLIKNATIONPROAM:  police car light SLIK WIT IT MATCHING UP FOR SEASON 7 police car light https://t.co/Pq0JpQQUTe  @youFamousEnough @MPBA2K  \n",
       "83                                                                                     RT @Joey_0806: @OttoMatticBaby listening to your music before a game  fire  fire  fire   \n",
       "128  Water delivery. Members of the  flag: Puerto Rico  #NationalGuard distribute  potable water  for the #Utuado community following #HurricaneMaria. https://t.co/OGGKrLVZ8j  \n",
       "171                           @vex1zgooner @ManUtd @Arsenal Well it is cos United fans are Wenger In.  face with tears of joy  face with tears of joy  face with tears of joy   "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mini[['content','content2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Transformer Testing\n",
    "\n",
    "Testing transformer on '`df_mini`'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp38-cp38-macosx_10_11_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.50.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (3.7.4.3)\n",
      "Collecting packaging>=20.0\n",
      "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Installing collected packages: tokenizers, packaging, huggingface-hub, transformers\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.4\n",
      "    Uninstalling packaging-20.4:\n",
      "      Successfully uninstalled packaging-20.4\n",
      "Successfully installed huggingface-hub-0.12.0 packaging-23.0 tokenizers-0.13.2 transformers-4.26.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c36ec51555d49ffa144d3baa7735042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading (‚Ä¶)lve/main/config.json'), FloatProgress(value=0.0, max=629.0), HTML(va‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-9e131caa06eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentiment-analysis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I've been waiting for a HuggingFace course my whole life.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;31m# Will load the correct model if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[0mmodel_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m     framework, model = infer_framework_load_model(\n\u001b[0m\u001b[1;32m    755\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mmodel_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \"\"\"\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0;34m\"At least one of TensorFlow 2.0 or PyTorch should be installed. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;34m\"To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "65a6dd32d71ed4a2e5ac9ab3f52d3aeee49f01a00467a63b19dc274a1d27154b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
