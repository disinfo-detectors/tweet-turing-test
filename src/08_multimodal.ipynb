{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "add0cef4-a4de-47c5-a9a0-e6b818d6fa2d",
   "metadata": {},
   "source": [
    "# Tweet Turing Test: Detecting Disinformation on Twitter  \n",
    "\n",
    "|          | Group #2 - Disinformation Detectors                     |\n",
    "|---------:|---------------------------------------------------------|\n",
    "| Members  | John Johnson, Katy Matulay, Justin Minnion, Jared Rubin |\n",
    "| Notebook | `05_multimodal.ipynb`                                   |\n",
    "| Purpose  | Combining tabular data with a BERT transformer.         |\n",
    "\n",
    "(todo: description)\n",
    "\n",
    "*Assumptions*  \n",
    " - The dataset being used has binary class labels following convention: 0 = authentic tweet; 1 = troll tweet\n",
    " - The execution environment has internet access (to download models from huggingface.co)\n",
    " - The execution environment has a CUDA-capable GPU available\n",
    "\n",
    "*General Notes*\n",
    " - Notebook kernel must be completely restarted between runs to release reserved VRAM from the GPU.\n",
    " - Notebook contains our usual code to load dataset file from GCP bucket, but model files are always saved locally regardless of `local_or_cloud` setting.\n",
    " - Notebook is based on a [notebook by georgian-io (github.com)](https://github.com/georgian-io/Multimodal-Toolkit/blob/master/notebooks/text_w_tabular_classification.ipynb) from their [Multimodal-Toolkit repository (github.com)](https://github.com/georgian-io/Multimodal-Toolkit) and [accompanying blog post (medium.com)](https://medium.com/georgian-impact-blog/how-to-incorporate-tabular-data-with-huggingface-transformers-b70ac45fcfb4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a7349-cf9c-461b-aebd-de5542e2ded8",
   "metadata": {},
   "source": [
    "# 1 - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d88ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm installed version of `transformers` matches the version required by `multimodal_transformers`\n",
    "supported_transformers_versions = {'4.25.1', '4.26.1'}\n",
    "\n",
    "import transformers\n",
    "assert (transformers.__version__ in supported_transformers_versions), \\\n",
    "    \"Unsupported version of 'transformers' installed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54c0673b-7027-407e-8435-e29090105df9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports from Python standard library\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import shutil\n",
    "import zipfile\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Optional\n",
    "\n",
    "# imports requiring installation\n",
    "#   connection to Google Cloud Storage\n",
    "from google.cloud import storage            # pip install google-cloud-storage\n",
    "from google.oauth2 import service_account   # pip install google-auth\n",
    "\n",
    "#  data science packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pynvml import *    # for debugging\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, auc, brier_score_loss, confusion_matrix, f1_score, precision_recall_curve, \n",
    "    precision_score, recall_score, roc_auc_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import softmax\n",
    "\n",
    "# ðŸ¤— (Hugging Face) packages\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoConfig, AutoModel, \n",
    "    BertTokenizerFast, DistilBertTokenizerFast, RobertaTokenizerFast, BertweetTokenizer, XLMRobertaTokenizerFast,\n",
    "    TrainingArguments, Trainer, EvalPrediction, \n",
    "    set_seed\n",
    ")\n",
    "\n",
    "# Georgian packages\n",
    "from multimodal_transformers.data.load_data import load_train_val_test_helper   # shhh, didn't have a leading underscore\n",
    "from multimodal_transformers.model import (\n",
    "    TabularConfig, AutoModelWithTabular, BertWithTabular, DistilBertWithTabular, RobertaWithTabular\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7494318-b0ee-4452-80fa-c959050a6c70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports from tweet_turing.py\n",
    "import tweet_turing as tur      # note - different import approach from prior notebooks\n",
    "\n",
    "# imports from tweet_turing_paths.py\n",
    "from tweet_turing_paths import local_data_paths, local_snapshot_paths, gcp_data_paths, \\\n",
    "    gcp_snapshot_paths, gcp_project_name, gcp_bucket_name, gcp_key_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee18cdf-9d6c-4315-90ad-3e470718b1e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pandas options\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7124b0f-b27f-450a-ba49-f0560c5b38b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Local or Cloud?\n",
    "\n",
    "Decide here whether to run notebook with local data or GCP bucket data\n",
    " - if the working directory of this notebook has a \"../data/\" folder with data loaded (e.g. working on local computer or have data files loaded to a cloud VM) then use the \"local files\" option and comment out the \"gcp bucket files\" option\n",
    " - if this notebook is being run from a GCP VM (preferrably in the `us-central1` location) then use the \"gcp bucket files\" option and comment out the \"local files\" option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d579d5d-f289-4b49-a1aa-f72f04d503b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# option: local files\n",
    "local_or_cloud: str = \"local\"   # comment/uncomment this line or next\n",
    "\n",
    "# option: gcp bucket files\n",
    "#local_or_cloud: str = \"cloud\"   # comment/uncomment this line or previous\n",
    "\n",
    "# don't comment/uncomment for remainder of cell\n",
    "if (local_or_cloud == \"local\"):\n",
    "    data_paths = local_data_paths\n",
    "    snapshot_paths = local_snapshot_paths\n",
    "elif (local_or_cloud == \"cloud\"):\n",
    "    data_paths = gcp_data_paths\n",
    "    snapshot_paths = gcp_snapshot_paths\n",
    "else:\n",
    "    raise ValueError(\"Variable 'local_or_cloud' can only take on one of two values, 'local' or 'cloud'.\")\n",
    "    # subsequent cells will not do this final \"else\" check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b206dfc-7e39-49a1-a48d-71a4cb46e863",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this cell only needs to run its code if local_or_cloud==\"cloud\"\n",
    "#   (though it is harmless if run when local_or_cloud==\"local\")\n",
    "gcp_storage_client: storage.Client = None\n",
    "gcp_bucket: storage.Bucket = None\n",
    "\n",
    "if (local_or_cloud == \"cloud\"):\n",
    "    gcp_storage_client = tur.get_gcp_storage_client(project_name=gcp_project_name, key_file=gcp_key_file)\n",
    "    gcp_bucket = tur.get_gcp_bucket(storage_client=gcp_storage_client, bucket_name=gcp_bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46318833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "# from huggingface tutorial: https://huggingface.co/docs/transformers/perf_train_gpu_one#efficient-training-on-a-single-gpu\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fa7ee9f-857e-4c69-bd3f-803a970c3199",
   "metadata": {},
   "source": [
    "# 2 - Load Dataset\n",
    "\n",
    "Starting with the full dataset (with engineered features) from notebook **`06_feature_engineering.ipynb`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47e19c3b-cab5-4e4c-a6b8-950f4c0dbc58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# note this cell requires package `pyarrow` to be installed in environment\n",
    "parq_filename: str = \"06data_full_final_en2.parquet.gz\"\n",
    "parq_path = Path(snapshot_paths['parq_snapshot'], parq_filename)\n",
    "\n",
    "if (local_or_cloud == \"local\"):\n",
    "    df_full = pd.read_parquet(parq_path, engine='pyarrow')\n",
    "elif (local_or_cloud == \"cloud\"):\n",
    "    df_full = tur.get_gcp_object_from_parq_as_df(bucket=gcp_bucket, object_name=parq_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96506d5c-cd41-4382-9518-55132bfad5d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3596578 entries, 0 to 3596577\n",
      "Data columns (total 54 columns):\n",
      " #   Column                         Dtype  \n",
      "---  ------                         -----  \n",
      " 0   external_author_id             string \n",
      " 1   author                         string \n",
      " 2   following                      int64  \n",
      " 3   followers                      int64  \n",
      " 4   updates                        int64  \n",
      " 5   is_retweet                     int64  \n",
      " 6   tweet_id                       string \n",
      " 7   has_url                        int64  \n",
      " 8   emoji_count                    int64  \n",
      " 9   following_ratio                float64\n",
      " 10  class_numeric                  int8   \n",
      " 11  RUS_lett_count                 int64  \n",
      " 12  emoji_flagUS                   int64  \n",
      " 13  emoji_police                   int64  \n",
      " 14  emoji_check                    int64  \n",
      " 15  emoji_exclamation              int64  \n",
      " 16  emoji_fist                     int64  \n",
      " 17  emoji_collision                int64  \n",
      " 18  emoji_prohibited               int64  \n",
      " 19  emoji_loudcryface              int64  \n",
      " 20  emoji_smilinghearteye          int64  \n",
      " 21  emoji_fire                     int64  \n",
      " 22  emoji_redheart                 int64  \n",
      " 23  emoji_tearsjoy                 int64  \n",
      " 24  emoji_thumbsup                 int64  \n",
      " 25  emoji_claphands                int64  \n",
      " 26  emoji_blowingkiss              int64  \n",
      " 27  emoji_partypop                 int64  \n",
      " 28  emoji_raisehands               int64  \n",
      " 29  region_United_States           int64  \n",
      " 30  region_Unknown                 int64  \n",
      " 31  region_New_York_NY             int64  \n",
      " 32  region_United_Kingdom          int64  \n",
      " 33  region_Los_Angeles_CA          int64  \n",
      " 34  region_Boston_MA               int64  \n",
      " 35  region_London                  int64  \n",
      " 36  region_New_York_and_the_World  int64  \n",
      " 37  region_New_York_City           int64  \n",
      " 38  region_Pale_Blue_Dot           int64  \n",
      " 39  region_Atlanta_GA              int64  \n",
      " 40  region_Australia               int64  \n",
      " 41  region_Global                  int64  \n",
      " 42  region_Washington_DC           int64  \n",
      " 43  region_All_Other               int64  \n",
      " 44  multi_authors                  int64  \n",
      " 45  num_dashes                     int64  \n",
      " 46  num_commas                     int64  \n",
      " 47  num_hashs                      int64  \n",
      " 48  num_URLs                       int64  \n",
      " 49  median_word_length             float64\n",
      " 50  cleaned_tweet                  object \n",
      " 51  sentiment                      float64\n",
      " 52  emoji_sentiment                float64\n",
      " 53  tweet_length                   int64  \n",
      "dtypes: float64(4), int64(45), int8(1), object(1), string(3)\n",
      "memory usage: 2.5 GB\n"
     ]
    }
   ],
   "source": [
    "df_full.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddf47eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make a smaller slice of full dataset for testing\n",
    "# n_tweets = 100000\n",
    "\n",
    "# df_small = df_full.groupby(by='class_numeric').sample(n=(n_tweets//2), random_state=42).reset_index()\n",
    "\n",
    "# # confirm stratefied\n",
    "# df_small['class_numeric'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "808911e9",
   "metadata": {},
   "source": [
    "# 3 - Setup Experimental Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf46bdf6",
   "metadata": {},
   "source": [
    "## 3.1 - Define dataclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0458b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataclasses to store the experiment parameters\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    model_name_or_path: str = field()\n",
    "    config_name:  Optional[str] = field(default=None)\n",
    "    tokenizer_name: Optional[str] = field(default=None)\n",
    "    cache_dir: Optional[str] = field(default=None)\n",
    "    num_labels: int = field(default=2)\n",
    "\n",
    "@dataclass\n",
    "class MultimodalDataTrainingArguments:\n",
    "    #data_path: str = field()\n",
    "    data_df: pd.DataFrame = field()     # modified to use dataframe\n",
    "\n",
    "    column_info_path: str = field(default=None)\n",
    "    column_info: dict = field(default=None)\n",
    "\n",
    "    categorical_encode_type: str = field(default='ohe')\n",
    "    numerical_transform_method: str = field(default='yeo_johnson')\n",
    "    \n",
    "    task: str = field(default='classification')\n",
    "    mlp_division: int = field(default=4)\n",
    "    combine_feat_method: str = field(default='individual_mlps_on_cat_and_numerical_feats_then_concat')\n",
    "    mlp_dropout: float = field(default=0.1)\n",
    "    numerical_bn: bool = field(default=True)\n",
    "    use_simple_classifier: str = field(default=True)\n",
    "    mlp_act: str = field(default='relu')\n",
    "    gating_beta: float = field(default=0.2)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        assert self.column_info != self.column_info_path\n",
    "        if (self.column_info is None and self.column_info_path):\n",
    "            with open(self.column_info_path, mode='r') as f:\n",
    "                self.column_info = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87412485",
   "metadata": {},
   "source": [
    "## 3.2 - Select Data / Model / Training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccebbc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model choices available\n",
    "multimodal_model_classes = {\n",
    "    # key = (huggingface) model name\n",
    "    # val = multimodal-transformers ModelWithTabular class (each a subclass of their respective ModelForSequenceClassification)\n",
    "    'bert-base-uncased': BertWithTabular,\n",
    "    'distilbert-base-uncased': DistilBertWithTabular,\n",
    "    'roberta-base': RobertaWithTabular,\n",
    "    'vinai/bertweet-base': RobertaWithTabular,\n",
    "    'Twitter/twhin-bert-base': BertWithTabular, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fe2e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Select the fine_tuned model\n",
    "fine_tuned_models_folder = '../data/models/'\n",
    "selected_model_folder_name = 'roberta-base-200k'  # no error checking implemented so type carefully\n",
    "base_hf_model_name = 'roberta-base'  # select from keys of `multimodal_model_classes` above\n",
    "\n",
    "model_path = Path(fine_tuned_models_folder, selected_model_folder_name)\n",
    "model_class = multimodal_model_classes[base_hf_model_name]\n",
    "\n",
    "# Step 2 - (mostly automatic) Choose a descriptive run name for this training/model.\n",
    "#   Suggested format: multimodal__[fine-tuned-model-name]__[YYYY-MM-DD]\n",
    "stub = selected_model_folder_name # 'distilbert-base-uncased-50k'\n",
    "date = pd.Timestamp.now().strftime(format=r\"%Y-%m-%d\")\n",
    "run_name = f\"multi-modal__{stub}__{date}\"\n",
    "\n",
    "# Step 3 - (mostly automatic) Choose a folder name for where to store the output of the model\n",
    "#   Will be created as a subfolder of `../data/models/multimodal`\n",
    "output_dir_name = f\"multi-modal__{stub}\"\n",
    "\n",
    "# Step 4 - Choose which columns from dataframe will be used.\n",
    "label_col = 'class_numeric'\n",
    "text_cols = ['cleaned_tweet']\n",
    "categorical_cols = [\n",
    "    'is_retweet',\n",
    "    'has_url',\n",
    "    'emoji_flagUS',\n",
    "    'emoji_police',\n",
    "    'emoji_check',\n",
    "    'emoji_exclamation',\n",
    "    'emoji_fist',\n",
    "    'emoji_collision',\n",
    "    'emoji_prohibited',\n",
    "    'emoji_loudcryface',\n",
    "    'emoji_smilinghearteye',\n",
    "    'emoji_fire',\n",
    "    'emoji_redheart',\n",
    "    'emoji_tearsjoy',\n",
    "    'emoji_thumbsup',\n",
    "    'emoji_claphands',\n",
    "    'emoji_blowingkiss',\n",
    "    'emoji_partypop',\n",
    "    'emoji_raisehands',\n",
    "    'region_United_States',\n",
    "    'region_Unknown',\n",
    "    'region_New_York_NY',\n",
    "    'region_United_Kingdom',\n",
    "    'region_Los_Angeles_CA',\n",
    "    'region_Boston_MA',\n",
    "    'region_London',\n",
    "    'region_New_York_and_the_World',\n",
    "    'region_New_York_City',\n",
    "    'region_Pale_Blue_Dot',\n",
    "    'region_Atlanta_GA',\n",
    "    'region_Australia',\n",
    "    'region_Global',\n",
    "    'region_Washington_DC',\n",
    "    'region_All_Other',\n",
    "    'multi_authors',\n",
    "]\n",
    "numericical_cols = [\n",
    "    'following', \n",
    "    'followers',\n",
    "    'updates',\n",
    "    'emoji_count',\n",
    "    'following_ratio',\n",
    "    'RUS_lett_count',\n",
    "    'num_dashes',\n",
    "    'num_commas',\n",
    "    'num_hashs',\n",
    "    'num_URLs',\n",
    "    'median_word_length',\n",
    "    'sentiment',\n",
    "    'emoji_sentiment',\n",
    "    'tweet_length',\n",
    "]\n",
    "\n",
    "# don't edit this\n",
    "column_info_dict = {\n",
    "    'text_cols': text_cols,\n",
    "    'num_cols': numericical_cols,\n",
    "    'cat_cols': categorical_cols,\n",
    "    'label_col': label_col,\n",
    "    'label_list': ['Authentic', 'Troll']\n",
    "}\n",
    "\n",
    "# Step 5 - specify dataset's dataframe and how many rows from dataset to feed\n",
    "#   also stratify by `label_col`\n",
    "n_rows = 1000000\n",
    "dataset_dataframe = df_full.groupby(by=label_col).sample(n=(n_rows//2), random_state=42).reset_index()\n",
    "#dataset_dataframe = df_full\n",
    "\n",
    "# Step 6 - Set model arguments\n",
    "model_args = ModelArguments(\n",
    "    model_name_or_path=model_path,\n",
    "    tokenizer_name=base_hf_model_name,\n",
    "    config_name=base_hf_model_name,\n",
    "    num_labels=2,\n",
    ")\n",
    "\n",
    "# Step 7 - Set data arguments\n",
    "data_args = MultimodalDataTrainingArguments(\n",
    "    data_df=dataset_dataframe,\n",
    "    combine_feat_method='weighted_feature_sum_on_transformer_cat_and_numerical_feats',\n",
    "    column_info=column_info_dict,\n",
    "    task='classification',\n",
    "    categorical_encode_type=None,\n",
    "    numerical_transform_method=\"yeo_johnson\",\n",
    "    #use_simple_classifier=False,\n",
    ")\n",
    "\n",
    "# Step 8 - Set training arguments\n",
    "multimodal_parent_output_dir = '../data/models/multimodal/'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    ## file args\n",
    "    run_name=run_name,\n",
    "    output_dir=Path(multimodal_parent_output_dir, output_dir_name),\n",
    "    logging_dir=Path(multimodal_parent_output_dir, output_dir_name, \"runs\"),\n",
    "    overwrite_output_dir=True,\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=1,\n",
    "    ## training hyperparams\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=160,\n",
    "    per_device_eval_batch_size=160,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,   # comment out this line for DistilBERT\n",
    "    weight_decay=0.01,\n",
    "    seed=42,\n",
    "    ## eval/log strategies\n",
    "    evaluation_strategy='epoch',\n",
    "    logging_strategy='epoch',\n",
    "    log_level='warning',\n",
    "    disable_tqdm=False,\n",
    ")\n",
    "\n",
    "set_seed(training_args.seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86cedf60",
   "metadata": {},
   "source": [
    "## 3.2 - Setup Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9715405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model class specified:\t'roberta-base'\n",
      "Tokenizer class chosen:\t'RobertaTokenizerFast'\n"
     ]
    }
   ],
   "source": [
    "# use tokenizer associated with our chosen model type\n",
    "#   - let AutoTokenizer pick the class for now but confirm the expected one gets picked\n",
    "#       - BERTbase      -> BertTokenizerFast\n",
    "#       - DistilBERT    -> DistilBertTokenizerFast\n",
    "#       - RoBERTA       -> RobertaTokenizerFast\n",
    "#       - BERTweet      -> BertweetTokenizer\n",
    "#       - TwHIN-BERT    -> XLMRobertaTokenizerFast\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_args.tokenizer_name)\n",
    "print(f\"Model class specified:\\t'{model_args.tokenizer_name}'\")\n",
    "print(f\"Tokenizer class chosen:\\t'{tokenizer.__class__.__name__}'\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f3ad92a",
   "metadata": {},
   "source": [
    "## 3.3 - Training / Validation / Test Split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4898afa8",
   "metadata": {},
   "source": [
    "### 3.3.1 - Filter out any tweets that were used for fine tuning\n",
    "\n",
    "Especially important for testing and validation datasets to filter these out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "660fbc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets filtered out:   68,177\n"
     ]
    }
   ],
   "source": [
    "# check for a file `fine_tune_tweet_ids.json` within fine-tuned model directory\n",
    "fine_tuned_tweets_filename = 'fine_tune_tweet_ids.json'\n",
    "fine_tuned_tweets_file = Path(model_args.model_name_or_path, fine_tuned_tweets_filename)\n",
    "\n",
    "if (not fine_tuned_tweets_file.exists()):\n",
    "    print(\"Heads up: no fine-tuned tweet file found at\", fine_tuned_tweets_file)\n",
    "else:\n",
    "    # load the list of tweets already used for fine-tuning\n",
    "    tweet_id_list = json.load(fine_tuned_tweets_file.open(encoding='utf-8'))\n",
    "\n",
    "    # filter the dataframe\n",
    "    filtered_df = data_args.data_df.loc[~data_args.data_df['tweet_id'].isin(tweet_id_list)]\n",
    "\n",
    "    # calculate delta\n",
    "    delta_tweets = data_args.data_df.shape[0] - filtered_df.shape[0]\n",
    "    print(f\"Number of tweets filtered out:{delta_tweets:>9,}\")\n",
    "\n",
    "    # re-assign the filtered datafram\n",
    "    data_args.data_df = filtered_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf08e4a3",
   "metadata": {},
   "source": [
    "### 3.3.2 - Split (and Tokenize)\n",
    "\n",
    "The tokenizer defined above is invoked within `load_train_val_test_helper`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3c364a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:       652,276 samples\n",
      "Validation dataset:     139,774 samples\n",
      "Testing dataset:        139,773 samples\n"
     ]
    }
   ],
   "source": [
    "# aiming for a 70% / 15% / 15% split\n",
    "train_df, test_and_val_df = train_test_split(data_args.data_df, train_size=0.7, random_state=42, shuffle=True)\n",
    "test_df, val_df = train_test_split(test_and_val_df, train_size=0.5, shuffle=False)\n",
    "\n",
    "# using this helper function (potentially not intended for public interface) because it allows\n",
    "#   us to bring in our dataframe directly (rather than needing to import from CSV)\n",
    "train_dataset, val_dataset, test_dataset = load_train_val_test_helper(\n",
    "    train_df=train_df,\n",
    "    val_df=val_df,\n",
    "    test_df=test_df,\n",
    "    text_cols=data_args.column_info['text_cols'],\n",
    "    tokenizer=tokenizer,\n",
    "    label_col=data_args.column_info['label_col'],\n",
    "    label_list=data_args.column_info['label_list'],\n",
    "    categorical_cols=data_args.column_info['cat_cols'],\n",
    "    numerical_cols=data_args.column_info['num_cols'],\n",
    "    sep_text_token_str=tokenizer.sep_token,\n",
    "    categorical_encode_type=data_args.categorical_encode_type,\n",
    "    numerical_transformer_method=data_args.numerical_transform_method\n",
    ")\n",
    "\n",
    "print(f\"Training dataset:  {len(train_dataset):>12,} samples\")\n",
    "print(f\"Validation dataset:{len(val_dataset):>12,} samples\")\n",
    "print(f\"Testing dataset:   {len(test_dataset):>12,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f960cf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Dataset:\n",
      " {'input_ids': tensor([    0, 11329,  2923,  7782, 40702,   192,   114,    52,    64,  1955,\n",
      "           66,    99,   189,    33,  1102, 10683,   201,    10, 18695,   217,\n",
      "            5,  1421,  2733,   341,     2,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(0, dtype=torch.int8), 'cat_feats': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), 'numerical_feats': tensor([-1.5865,  1.3589, -1.1869, -0.1926, -1.0838, -0.0143, -0.4188, -0.5615,\n",
      "        -0.7714,  0.4211, -1.6025, -0.6013, -0.0566,  1.1331])}\n",
      "\n",
      ">> Origin DF:\n",
      " cleaned_tweet                    Thats strange Lets see if we can figure out what may have happened Send us a DM including the model iPhone used\n",
      "is_retweet                                                                                                                                     0\n",
      "has_url                                                                                                                                        1\n",
      "emoji_flagUS                                                                                                                                   0\n",
      "emoji_police                                                                                                                                   0\n",
      "emoji_check                                                                                                                                    0\n",
      "emoji_exclamation                                                                                                                              0\n",
      "emoji_fist                                                                                                                                     0\n",
      "emoji_collision                                                                                                                                0\n",
      "emoji_prohibited                                                                                                                               0\n",
      "emoji_loudcryface                                                                                                                              0\n",
      "emoji_smilinghearteye                                                                                                                          0\n",
      "emoji_fire                                                                                                                                     0\n",
      "emoji_redheart                                                                                                                                 0\n",
      "emoji_tearsjoy                                                                                                                                 0\n",
      "emoji_thumbsup                                                                                                                                 0\n",
      "emoji_claphands                                                                                                                                0\n",
      "emoji_blowingkiss                                                                                                                              0\n",
      "emoji_partypop                                                                                                                                 0\n",
      "emoji_raisehands                                                                                                                               0\n",
      "region_United_States                                                                                                                           0\n",
      "region_Unknown                                                                                                                                 0\n",
      "region_New_York_NY                                                                                                                             0\n",
      "region_United_Kingdom                                                                                                                          0\n",
      "region_Los_Angeles_CA                                                                                                                          0\n",
      "region_Boston_MA                                                                                                                               0\n",
      "region_London                                                                                                                                  0\n",
      "region_New_York_and_the_World                                                                                                                  0\n",
      "region_New_York_City                                                                                                                           0\n",
      "region_Pale_Blue_Dot                                                                                                                           0\n",
      "region_Atlanta_GA                                                                                                                              0\n",
      "region_Australia                                                                                                                               0\n",
      "region_Global                                                                                                                                  0\n",
      "region_Washington_DC                                                                                                                           0\n",
      "region_All_Other                                                                                                                               1\n",
      "multi_authors                                                                                                                                  0\n",
      "following                                                                                                                                     34\n",
      "followers                                                                                                                                1502435\n",
      "updates                                                                                                                                        2\n",
      "emoji_count                                                                                                                                    0\n",
      "following_ratio                                                                                                                         0.000023\n",
      "RUS_lett_count                                                                                                                                 0\n",
      "num_dashes                                                                                                                                     0\n",
      "num_commas                                                                                                                                     0\n",
      "num_hashs                                                                                                                                      0\n",
      "num_URLs                                                                                                                                       1\n",
      "median_word_length                                                                                                                           3.0\n",
      "sentiment                                                                                                                                -0.2023\n",
      "emoji_sentiment                                                                                                                              0.0\n",
      "tweet_length                                                                                                                                 111\n",
      "class_numeric                                                                                                                                  0\n",
      "Name: 154101, dtype: object\n",
      "\n",
      ">> Unique labels: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# check output\n",
    "print(\">> Dataset:\\n\", train_dataset[0], end=\"\\n\\n\")\n",
    "print(\">> Origin DF:\\n\", train_df.iloc[0][text_cols + categorical_cols + numericical_cols + [\"class_numeric\"]], end=\"\\n\\n\")\n",
    "\n",
    "print(f\">> Unique labels: {np.unique(train_dataset.labels)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d941b71a",
   "metadata": {},
   "source": [
    "## 3.4 - Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0869d42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelArguments(model_name_or_path=WindowsPath('../data/models/roberta-base-200k'),\n",
      "               config_name='roberta-base',\n",
      "               tokenizer_name='roberta-base',\n",
      "               cache_dir=None,\n",
      "               num_labels=2)\n"
     ]
    }
   ],
   "source": [
    "# help out with setup\n",
    "pprint(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85a80751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaWithTabular were not initialized from the model checkpoint at ..\\data\\models\\roberta-base-200k and are newly initialized: ['tabular_combiner.layer_norm.weight', 'tabular_combiner.num_bn.num_batches_tracked', 'tabular_combiner.num_bn.running_var', 'tabular_combiner.num_layer.bias', 'tabular_combiner.cat_layer.weight', 'tabular_combiner.weight_num', 'tabular_classifier.bias', 'tabular_combiner.weight_cat', 'tabular_combiner.num_bn.running_mean', 'tabular_combiner.num_layer.weight', 'tabular_combiner.num_bn.bias', 'tabular_classifier.weight', 'tabular_combiner.num_bn.weight', 'tabular_combiner.layer_norm.bias', 'tabular_combiner.cat_layer.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# make a ðŸ¤— transformer config\n",
    "config = AutoConfig.from_pretrained(model_args.config_name)\n",
    "\n",
    "# setup the multimodal-transformers-specific TabularConfig\n",
    "tabular_config = TabularConfig(\n",
    "    num_labels=model_args.num_labels,                           # default is 2\n",
    "    cat_feat_dim=train_dataset.cat_feats.shape[1],              # number of cat feature columns\n",
    "    numerical_feat_dim=train_dataset.numerical_feats.shape[1],  # number of num feature columns\n",
    "    **vars(data_args)                                           # dump in everything else as kwarg\n",
    ")\n",
    "\n",
    "# add TabularConfig to ðŸ¤— transformer config\n",
    "config.tabular_config = tabular_config\n",
    "\n",
    "# define which class we're going to use for model\n",
    "#model = DistilBertWithTabular.from_pretrained(\n",
    "model = model_class.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_args.model_name_or_path,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd246fad",
   "metadata": {},
   "source": [
    "## 3.5 - Setup Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daeff92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_binary_classification_metrics(eval_pred: EvalPrediction) -> dict[str, float]:\n",
    "    logits_obj, labels = eval_pred\n",
    "\n",
    "    if (isinstance(logits_obj, tuple)):\n",
    "        # not quite sure what is causing a tuple to be returned here but this line of code cost 3+ hours of sadness\n",
    "        logits=logits_obj[0]\n",
    "    else:\n",
    "        logits=logits_obj\n",
    "\n",
    "    # for each row of eval_pred, pick the larger column and return its column index (0 or 1)\n",
    "    #   - result looks like: [0, 1, 0, 0, 1, ...]\n",
    "    predictions_as_labels = np.argmax(logits, axis=1)   # axis=1 gives max column value in each row\n",
    "\n",
    "    # for each row of eval_pred, apply softmax to ~normalize as scores summing to 1, \n",
    "    #   and grab the probability of class=1 (i.e. second column of each row)\n",
    "    #   - result looks like: [0.993, 0.003, 0.234, ...]\n",
    "    predictions_as_probs = softmax(logits, axis=1)[:,1]\n",
    "\n",
    "    # binary classification metrics\n",
    "    #   label-based\n",
    "    metric_accuracy = accuracy_score(y_true=labels, y_pred=predictions_as_labels)\n",
    "    metric_f1score = f1_score(y_true=labels, y_pred=predictions_as_labels, zero_division=0)\n",
    "    metric_precision = precision_score(y_true=labels, y_pred=predictions_as_labels, zero_division=0)\n",
    "    metric_recall = recall_score(y_true=labels, y_pred=predictions_as_labels, zero_division=0)\n",
    "\n",
    "    #   probability-based\n",
    "    metric_roc_auc = roc_auc_score(y_true=labels, y_score=predictions_as_probs)\n",
    "    metric_brier = brier_score_loss(y_true=labels, y_prob=predictions_as_probs)\n",
    "\n",
    "    #   confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, predictions_as_labels, labels=[0, 1]).ravel()\n",
    "\n",
    "    # package up the results\n",
    "    result = {\n",
    "        'accuracy': metric_accuracy,\n",
    "        'f1score': metric_f1score,\n",
    "        'precision': metric_precision,\n",
    "        'recall': metric_recall,\n",
    "        'roc_auc': metric_roc_auc,\n",
    "        'brier_score': metric_brier,\n",
    "        'tn': tn.item(),\n",
    "        'fp': fp.item(),\n",
    "        'fn': fn.item(),\n",
    "        'tp': tp.item()\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65a56d80",
   "metadata": {},
   "source": [
    "## 3.6 - Setup / Run Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49fc9922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Justin\\.envs\\tf290_env\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efb5213d42843eab51bf3213ba9c2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3057 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1132, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7700b39e0cba479990f5ff59c51a5936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01712989993393421, 'eval_accuracy': 0.9983258689026572, 'eval_f1score': 0.9983473175692855, 'eval_precision': 0.9979667047909518, 'eval_recall': 0.9987282207808724, 'eval_roc_auc': 0.9999635338431926, 'eval_brier_score': 0.0023339306778908868, 'eval_tn': 68863, 'eval_fp': 144, 'eval_fn': 90, 'eval_tp': 70677, 'eval_runtime': 285.4048, 'eval_samples_per_second': 489.739, 'eval_steps_per_second': 3.062, 'epoch': 1.0}\n",
      "{'loss': 0.0096, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c41272d6f6434cb2d3647f44a2ed36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.006480858661234379, 'eval_accuracy': 0.9991557800449297, 'eval_f1score': 0.9991663134096368, 'eval_precision': 0.9991239597021463, 'eval_recall': 0.9992086707080984, 'eval_roc_auc': 0.999994177132113, 'eval_brier_score': 0.0009177940917554313, 'eval_tn': 68945, 'eval_fp': 62, 'eval_fn': 56, 'eval_tp': 70711, 'eval_runtime': 285.1189, 'eval_samples_per_second': 490.231, 'eval_steps_per_second': 3.065, 'epoch': 2.0}\n",
      "{'loss': 0.0044, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa0e16ffc9c4d2eb8d543e6880beddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.005546794272959232, 'eval_accuracy': 0.9991843976705252, 'eval_f1score': 0.9991946308724833, 'eval_precision': 0.9990817004082901, 'eval_recall': 0.9993075868695861, 'eval_roc_auc': 0.999979264320124, 'eval_brier_score': 0.0008191003349945584, 'eval_tn': 68942, 'eval_fp': 65, 'eval_fn': 49, 'eval_tp': 70718, 'eval_runtime': 285.5344, 'eval_samples_per_second': 489.517, 'eval_steps_per_second': 3.061, 'epoch': 3.0}\n",
      "{'train_runtime': 34809.6031, 'train_samples_per_second': 56.215, 'train_steps_per_second': 0.088, 'train_loss': 0.04240188717179178, 'epoch': 3.0}\n",
      "\n",
      "Training duration: 0 days 09:40:10.093864\n",
      "\n",
      "Time: 34809.60\n",
      "Samples/second: 56.22\n",
      "GPU memory occupied: 7861 MB.\n"
     ]
    }
   ],
   "source": [
    "time_training_start = pd.Timestamp.now()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_binary_classification_metrics\n",
    ")\n",
    "\n",
    "result = trainer.train()\n",
    "\n",
    "time_training_stop = pd.Timestamp.now()\n",
    "time_training = time_training_stop - time_training_start\n",
    "print(\"\\nTraining duration:\", str(time_training), end=\"\\n\\n\")\n",
    "\n",
    "# debug\n",
    "print_summary(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7aabf3ed",
   "metadata": {},
   "source": [
    "## 3.7 - Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71fba9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()    # defaults to self.args.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63964e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to delete '..\\data\\models\\multimodal\\multi-modal__roberta-base-200k/checkpoint-3057' ... success\n"
     ]
    }
   ],
   "source": [
    "# optional - delete checkpoint directories\n",
    "checkpoint_dirs = [\n",
    "    f\"{trainer.args.output_dir}/{directory}\"\n",
    "    for directory in os.listdir(trainer.args.output_dir)\n",
    "        if (\n",
    "            os.path.isdir(os.path.join(trainer.args.output_dir, directory))\n",
    "            and\n",
    "            directory.startswith('checkpoint')\n",
    "        )\n",
    "]\n",
    "\n",
    "for checkpoint_dir in checkpoint_dirs:\n",
    "    print(f\"Attempting to delete '{checkpoint_dir}' ...\", end='')\n",
    "    shutil.rmtree(checkpoint_dir)\n",
    "    print(f\" success\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0371be7",
   "metadata": {},
   "source": [
    "## 3.8 - Generate Model Predictions and Evaluate\n",
    "\n",
    "The `Trainer.predict()` method also calculates performance metrics so we'll cover both tasks with one loop through our test dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "737b266f",
   "metadata": {},
   "source": [
    "### 3.8.1 - Calculate Predictions with Test Dataset\n",
    "\n",
    "And save the predictions as JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5195ae2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6b39181e5d4e098fbc8e8e42ea3b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make predictions\n",
    "predictions_output = trainer.predict(test_dataset, metric_key_prefix='test')\n",
    "\n",
    "# predictions output is a subclass of NamedTuple, so to save to JSON we convert to a dict first\n",
    "#   Note: according to python docs, the leading underscore is to avoid name conflicts, not as the usual \"discouraged from use\" meaning\n",
    "#   Source: https://docs.python.org/3.10/library/collections.html#collections.somenamedtuple._asdict\n",
    "predictions_dict = predictions_output._asdict()\n",
    "\n",
    "# process the incoming object depending on its type\n",
    "if (isinstance(predictions_dict['predictions'], tuple)):\n",
    "    predictions = predictions_dict['predictions'][0]\n",
    "else:\n",
    "    predictions = predictions_dict['predictions']\n",
    "\n",
    "# overwrite the dict values with vanilla Python types\n",
    "predictions_dict['run_name'] = trainer.args.run_name\n",
    "predictions_dict['predictions'] = predictions.tolist()\n",
    "predictions_dict['label_ids'] = predictions_dict['label_ids'].tolist()\n",
    "\n",
    "# sort the keys\n",
    "dict_order = ['run_name', 'metrics', 'predictions', 'label_ids']\n",
    "predictions_dict = {key: predictions_dict[key] for key in dict_order}\n",
    "\n",
    "# save predictions to `output_dir`\n",
    "predictions_file = Path(trainer.args.output_dir, 'predictions.json')\n",
    "with predictions_file.open(mode='w', encoding='utf-8') as fp:\n",
    "    json.dump(predictions_dict, fp, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e162fe72",
   "metadata": {},
   "source": [
    "### 3.8.2 - Display and Save Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "274c7682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.005593133624643087,\n",
      " 'test_accuracy': 0.9991343106322395,\n",
      " 'test_f1score': 0.9991441565698361,\n",
      " 'test_precision': 0.9989957709226178,\n",
      " 'test_recall': 0.9992925863044708,\n",
      " 'test_roc_auc': 0.9999797125755825,\n",
      " 'test_brier_score': 0.0008616273300967795,\n",
      " 'test_tn': 69022,\n",
      " 'test_fp': 71,\n",
      " 'test_fn': 50,\n",
      " 'test_tp': 70630,\n",
      " 'test_runtime': 553.8012,\n",
      " 'test_samples_per_second': 252.388,\n",
      " 'test_steps_per_second': 1.578}\n"
     ]
    }
   ],
   "source": [
    "# display\n",
    "pprint(predictions_dict['metrics'], sort_dicts=False)\n",
    "\n",
    "# consolidate\n",
    "metrics_dict = {\n",
    "    'run_name': trainer.args.run_name,\n",
    "    'final_test_metrics': predictions_dict['metrics'],\n",
    "    'trainer_log': trainer.state.log_history\n",
    "}\n",
    "\n",
    "# save\n",
    "metrics_file = Path(trainer.args.output_dir, 'model_metrics.json')\n",
    "with metrics_file.open(mode='w', encoding='utf-8') as fp:\n",
    "    json.dump(metrics_dict, fp, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d338443a",
   "metadata": {},
   "source": [
    "### 3.8.3 - All The Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b129c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidate\n",
    "all_args = {\n",
    "    'run_name': trainer.args.run_name,\n",
    "    'column_info_dict': column_info_dict,\n",
    "    'data_args': {k: v for (k, v) in data_args.__dict__.items() if (k != 'data_df')},\n",
    "    'model_args': model_args.__dict__,\n",
    "    'training_args': training_args.__dict__\n",
    "}\n",
    "\n",
    "# fix args that doesn't json serialize\n",
    "all_args['model_args']['model_name_or_path'] = all_args['model_args']['model_name_or_path'].as_posix()\n",
    "all_args['training_args'][\"__cached__setup_devices\"] = str(all_args['training_args'][\"__cached__setup_devices\"])\n",
    "\n",
    "# save\n",
    "all_args_file = Path(trainer.args.output_dir, 'all_args.json')\n",
    "with all_args_file.open(mode='w', encoding='utf-8') as fp:\n",
    "    json.dump(all_args, fp, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "520283ee",
   "metadata": {},
   "source": [
    "### 3.8.4 - Tweet IDs used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b282330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids = {\n",
    "    'train': train_df['tweet_id'].to_list(),\n",
    "    'val': val_df['tweet_id'].to_list(),\n",
    "    'test': test_df['tweet_id'].to_list()\n",
    "}\n",
    "\n",
    "tweet_ids_filename = Path(trainer.args.output_dir, 'tweet_ids.json')\n",
    "with tweet_ids_filename.open(mode='w', encoding='utf-8') as fp:\n",
    "    json.dump(tweet_ids, fp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb284867",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m103"
  },
  "kernelspec": {
   "display_name": "tf290_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "65a6dd32d71ed4a2e5ac9ab3f52d3aeee49f01a00467a63b19dc274a1d27154b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
